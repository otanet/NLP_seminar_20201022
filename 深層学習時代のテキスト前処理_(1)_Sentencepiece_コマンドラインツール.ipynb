{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "深層学習時代のテキスト前処理:(1) Sentencepiece コマンドラインツール",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/otanet/NLP_seminar_20201022/blob/main/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E6%99%82%E4%BB%A3%E3%81%AE%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E5%89%8D%E5%87%A6%E7%90%86_(1)_Sentencepiece_%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89%E3%83%A9%E3%82%A4%E3%83%B3%E3%83%84%E3%83%BC%E3%83%AB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQHbKaayKVBj"
      },
      "source": [
        "# 深層学習時代のテキスト前処理:(1) Sentencepiece コマンドラインツール \n",
        "\n",
        "Sentencepiece （C++）版をビルド、インストールし、コマンドラインツールとしてサブワードの学習、トークン化(エンコード), 脱トークン化(デコード) を行います。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY82TcrNKXgs"
      },
      "source": [
        "## インストール\n",
        "\n",
        "sentencepiece のソースをgithub からダウンロードし、ビルド・インストールを行います。debian のパッケージ化が進んでいるため、近い将来 apt-get 経由でインストールできるかもしれません。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MnlkMJ3LMPe",
        "outputId": "23ea1bf2-b5b2-464c-c299-78f56c3f6625",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/google/sentencepiece.git\n",
        "%cd sentencepiece\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake ..\n",
        "!make -j20\n",
        "!make install\n",
        "!ldconfig\n",
        "!spm_train --help"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sentencepiece'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 3333 (delta 31), reused 36 (delta 16), pack-reused 3273\u001b[K\n",
            "Receiving objects: 100% (3333/3333), 27.06 MiB | 22.96 MiB/s, done.\n",
            "Resolving deltas: 100% (2308/2308), done.\n",
            "/content/sentencepiece\n",
            "/content/sentencepiece/build\n",
            "-- VERSION: 0.1.93\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Looking for pthread.h\n",
            "-- Looking for pthread.h - found\n",
            "-- Looking for pthread_create\n",
            "-- Looking for pthread_create - not found\n",
            "-- Looking for pthread_create in pthreads\n",
            "-- Looking for pthread_create in pthreads - not found\n",
            "-- Looking for pthread_create in pthread\n",
            "-- Looking for pthread_create in pthread - found\n",
            "-- Found Threads: TRUE  \n",
            "-- Not Found TCMalloc: TCMALLOC_LIB-NOTFOUND\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/sentencepiece/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target sentencepiece\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target sentencepiece_train-static\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target sentencepiece-static\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/arena.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/arenastring.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/bytestream.cc.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_message_table_driven_lite.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/extension_set.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/implicit_weak_message.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_message_util.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/int128.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/message_lite.cc.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/coded_stream.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/common.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/repeated_field.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/io_win32.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/arena.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/arenastring.cc.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/status.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/bytestream.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/statusor.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/stringpiece.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/builder.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/stringprintf.cc.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/structurally_valid.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/unicode_script.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/trainer_factory.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/strutil.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/unigram_model_trainer.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/trainer_interface.cc.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/word_model_trainer.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/char_model_trainer.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/bpe_model_trainer.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/time.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/coded_stream.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/common.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/extension_set.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/wire_format_lite.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/sentencepiece_trainer.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream.cc.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream_impl_lite.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/builtin_pb/sentencepiece.pb.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/generated_message_table_driven_lite.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/generated_message_util.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/implicit_weak_message.cc.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/builtin_pb/sentencepiece_model.pb.cc.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/bpe_model.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/char_model.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/int128.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/io_win32.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train-static.dir/pretokenizer_for_training.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/error.cc.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/filesystem.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/init.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/model_factory.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/model_interface.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/normalizer.cc.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/message_lite.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/sentencepiece_processor.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/repeated_field.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/status.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/unigram_model.cc.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/util.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/word_model.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/statusor.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/absl/strings/string_view.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/absl/flags/flag.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/stringpiece.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/stringprintf.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/structurally_valid.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/strutil.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/time.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/wire_format_lite.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/zero_copy_stream.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/zero_copy_stream_impl_lite.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/builtin_pb/sentencepiece.pb.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/builtin_pb/sentencepiece_model.pb.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/bpe_model.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/char_model.cc.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/error.cc.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/filesystem.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/init.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/model_factory.cc.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/model_interface.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/normalizer.cc.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/sentencepiece_processor.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/unigram_model.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/util.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/word_model.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/absl/strings/string_view.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/absl/flags/flag.cc.o\u001b[0m\n",
            "[ 79%] \u001b[32m\u001b[1mLinking CXX static library libsentencepiece.a\u001b[0m\n",
            "[ 79%] Built target sentencepiece-static\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX shared library libsentencepiece.so\u001b[0m\n",
            "[ 80%] Built target sentencepiece\n",
            "\u001b[35m\u001b[1mScanning dependencies of target spm_decode\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target spm_encode\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target spm_export_vocab\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target sentencepiece_train\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object src/CMakeFiles/spm_decode.dir/spm_decode_main.cc.o\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object src/CMakeFiles/spm_export_vocab.dir/spm_export_vocab_main.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object src/CMakeFiles/spm_encode.dir/spm_encode_main.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/builder.cc.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/unicode_script.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/word_model_trainer.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/unigram_model_trainer.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/bpe_model_trainer.cc.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/trainer_factory.cc.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/char_model_trainer.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/trainer_interface.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/sentencepiece_trainer.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object src/CMakeFiles/sentencepiece_train.dir/pretokenizer_for_training.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX executable spm_export_vocab\u001b[0m\n",
            "[ 92%] Built target spm_export_vocab\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable spm_decode\u001b[0m\n",
            "[ 93%] Built target spm_decode\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX executable spm_encode\u001b[0m\n",
            "[ 94%] Built target spm_encode\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX static library libsentencepiece_train.a\u001b[0m\n",
            "[ 95%] Built target sentencepiece_train-static\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX shared library libsentencepiece_train.so\u001b[0m\n",
            "[ 96%] Built target sentencepiece_train\n",
            "\u001b[35m\u001b[1mScanning dependencies of target spm_normalize\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target spm_train\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object src/CMakeFiles/spm_train.dir/spm_train_main.cc.o\u001b[0m\n",
            "[ 98%] \u001b[32mBuilding CXX object src/CMakeFiles/spm_normalize.dir/spm_normalize_main.cc.o\u001b[0m\n",
            "[ 99%] \u001b[32m\u001b[1mLinking CXX executable spm_normalize\u001b[0m\n",
            "[ 99%] Built target spm_normalize\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable spm_train\u001b[0m\n",
            "[100%] Built target spm_train\n",
            "[ 35%] Built target sentencepiece\n",
            "[ 45%] Built target sentencepiece_train-static\n",
            "[ 47%] Built target spm_encode\n",
            "[ 57%] Built target sentencepiece_train\n",
            "[ 59%] Built target spm_train\n",
            "[ 60%] Built target spm_decode\n",
            "[ 62%] Built target spm_normalize\n",
            "[ 98%] Built target sentencepiece-static\n",
            "[100%] Built target spm_export_vocab\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"\"\n",
            "-- Installing: /usr/local/lib/pkgconfig/sentencepiece.pc\n",
            "-- Installing: /usr/local/lib/libsentencepiece.so.0.0.0\n",
            "-- Installing: /usr/local/lib/libsentencepiece.so.0\n",
            "-- Installing: /usr/local/lib/libsentencepiece.so\n",
            "-- Installing: /usr/local/lib/libsentencepiece_train.so.0.0.0\n",
            "-- Installing: /usr/local/lib/libsentencepiece_train.so.0\n",
            "-- Set runtime path of \"/usr/local/lib/libsentencepiece_train.so.0.0.0\" to \"\"\n",
            "-- Installing: /usr/local/lib/libsentencepiece_train.so\n",
            "-- Installing: /usr/local/lib/libsentencepiece.a\n",
            "-- Installing: /usr/local/lib/libsentencepiece_train.a\n",
            "-- Installing: /usr/local/bin/spm_encode\n",
            "-- Set runtime path of \"/usr/local/bin/spm_encode\" to \"\"\n",
            "-- Installing: /usr/local/bin/spm_decode\n",
            "-- Set runtime path of \"/usr/local/bin/spm_decode\" to \"\"\n",
            "-- Installing: /usr/local/bin/spm_normalize\n",
            "-- Set runtime path of \"/usr/local/bin/spm_normalize\" to \"\"\n",
            "-- Installing: /usr/local/bin/spm_train\n",
            "-- Set runtime path of \"/usr/local/bin/spm_train\" to \"\"\n",
            "-- Installing: /usr/local/bin/spm_export_vocab\n",
            "-- Set runtime path of \"/usr/local/bin/spm_export_vocab\" to \"\"\n",
            "-- Installing: /usr/local/include/sentencepiece_trainer.h\n",
            "-- Installing: /usr/local/include/sentencepiece_processor.h\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "sentencepiece\n",
            "\n",
            "Usage: spm_train [options] files\n",
            "\n",
            "   --help (show help)  type: bool default: false\n",
            "   --version (show version)  type: bool default: false\n",
            "   --minloglevel (Messages logged at a lower level than this don't actually get logged anywhere)  type: int default: 0\n",
            "   --input (comma separated list of input sentences)  type: std::string default: \"\"\n",
            "   --input_format (Input format. Supported format is `text` or `tsv`.)  type: std::string default: \"\"\n",
            "   --model_prefix (output model prefix)  type: std::string default: \"\"\n",
            "   --model_type (model algorithm: unigram, bpe, word or char)  type: std::string default: \"unigram\"\n",
            "   --vocab_size (vocabulary size)  type: int32 default: 8000\n",
            "   --accept_language (comma-separated list of languages this model can accept)  type: std::string default: \"\"\n",
            "   --self_test_sample_size (the size of self test samples)  type: int32 default: 0\n",
            "   --character_coverage (character coverage to determine the minimum symbols)  type: double default: 0.9995\n",
            "   --input_sentence_size (maximum size of sentences the trainer loads)  type: int32 default: 0\n",
            "   --shuffle_input_sentence (Randomly sample input sentences in advance. Valid when --input_sentence_size > 0)  type: bool default: true\n",
            "   --seed_sentencepiece_size (the size of seed sentencepieces)  type: int32 default: 1000000\n",
            "   --shrinking_factor (Keeps top shrinking_factor pieces with respect to the loss)  type: double default: 0.75\n",
            "   --num_threads (number of threads for training)  type: int32 default: 16\n",
            "   --num_sub_iterations (number of EM sub-iterations)  type: int32 default: 2\n",
            "   --max_sentencepiece_length (maximum length of sentence piece)  type: int32 default: 16\n",
            "   --max_sentence_length (maximum length of sentence in byte)  type: int32 default: 4192\n",
            "   --split_by_unicode_script (use Unicode script to split sentence pieces)  type: bool default: true\n",
            "   --split_by_number (split tokens by numbers (0-9))  type: bool default: true\n",
            "   --split_by_whitespace (use a white space to split sentence pieces)  type: bool default: true\n",
            "   --split_digits (split all digits (0-9) into separate pieces)  type: bool default: false\n",
            "   --treat_whitespace_as_suffix (treat whitespace marker as suffix instead of prefix.)  type: bool default: false\n",
            "   --control_symbols (comma separated list of control symbols)  type: std::string default: \"\"\n",
            "   --control_symbols_file (load control_symbols from file.)  type: std::string default: \"\"\n",
            "   --user_defined_symbols (comma separated list of user defined symbols)  type: std::string default: \"\"\n",
            "   --user_defined_symbols_file (load user_defined_symbols from file.)  type: std::string default: \"\"\n",
            "   --required_chars (UTF8 characters in this flag are always used in the character set regardless of --character_coverage)  type: std::string default: \"\"\n",
            "   --required_chars_file (load required_chars from file.)  type: std::string default: \"\"\n",
            "   --byte_fallback (decompose unknown pieces into UTF-8 byte pieces)  type: bool default: false\n",
            "   --vocabulary_output_piece_score (Define score in vocab file)  type: bool default: true\n",
            "   --normalization_rule_name (Normalization rule name. Choose from nfkc or identity)  type: std::string default: \"nmt_nfkc\"\n",
            "   --normalization_rule_tsv (Normalization rule TSV file. )  type: std::string default: \"\"\n",
            "   --denormalization_rule_tsv (Denormalization rule TSV file.)  type: std::string default: \"\"\n",
            "   --add_dummy_prefix (Add dummy whitespace at the beginning of text)  type: bool default: true\n",
            "   --remove_extra_whitespaces (Removes leading, trailing, and duplicate internal whitespace)  type: bool default: true\n",
            "   --hard_vocab_limit (If set to false, --vocab_size is considered as a soft limit.)  type: bool default: true\n",
            "   --use_all_vocab (If set to true, use all tokens as vocab. Valid for word/char models.)  type: bool default: false\n",
            "   --unk_id (Override UNK (<unk>) id.)  type: int32 default: 0\n",
            "   --bos_id (Override BOS (<s>) id. Set -1 to disable BOS.)  type: int32 default: 1\n",
            "   --eos_id (Override EOS (</s>) id. Set -1 to disable EOS.)  type: int32 default: 2\n",
            "   --pad_id (Override PAD (<pad>) id. Set -1 to disable PAD.)  type: int32 default: -1\n",
            "   --unk_piece (Override UNK (<unk>) piece.)  type: std::string default: \"<unk>\"\n",
            "   --bos_piece (Override BOS (<s>) piece.)  type: std::string default: \"<s>\"\n",
            "   --eos_piece (Override EOS (</s>) piece.)  type: std::string default: \"</s>\"\n",
            "   --pad_piece (Override PAD (<pad>) piece.)  type: std::string default: \"<pad>\"\n",
            "   --unk_surface (Dummy surface string for <unk>. In decoding <unk> is decoded to `unk_surface`.)  type: std::string default: \" ⁇ \"\n",
            "   --train_extremely_large_corpus (Increase bit depth for unigram tokenization.)  type: bool default: false\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7laKUh1yMSab"
      },
      "source": [
        "## サブワードモデルの学習\n",
        "\n",
        "「吾輩は猫である」のサンプル文書を(sentencepiece/data/wagahaiwa_nekodearu.txt)用いて、サブワードモデルを学習します。\n",
        "\n",
        "学習には spm_train コマンドを用います。最低限以下のオプションを与えます\n",
        "\n",
        "\n",
        "*   --vocab_size=8000:  サブワードの語彙サイズ\n",
        "*   --input=sentencepiece/data/wagahaiwa_nekodearu.txt: 学習データ(一文一行)\n",
        "*   --model_prefix=m: 出力モデルファイル (m.model/m.vocabファイルが作成されます。)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kNZ17CdNSTi",
        "outputId": "7816743e-0c09-4a11-88a5-6baa732e31cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd ..\n",
        "!spm_train --vocab_size=8000 --input=data/wagahaiwa_nekodearu.txt --model_prefix=m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/sentencepiece\n",
            "sentencepiece_trainer.cc(79) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: data/wagahaiwa_nekodearu.txt\n",
            "  input_format: \n",
            "  model_prefix: m\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 8000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(320) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(175) LOG(INFO) Loading corpus: data/wagahaiwa_nekodearu.txt\n",
            "trainer_interface.cc(347) LOG(WARNING) Found too long line (4333 > 4192).\n",
            "trainer_interface.cc(349) LOG(WARNING) Too long lines are skipped in the training.\n",
            "trainer_interface.cc(350) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
            "trainer_interface.cc(376) LOG(INFO) Loaded all 2294 sentences\n",
            "trainer_interface.cc(382) LOG(INFO) Skipped 50 too long sentences.\n",
            "trainer_interface.cc(391) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(391) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(391) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(396) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(457) LOG(INFO) all chars count=257267\n",
            "trainer_interface.cc(468) LOG(INFO) Done: 99.9502% characters are covered.\n",
            "trainer_interface.cc(478) LOG(INFO) Alphabet size=2730\n",
            "trainer_interface.cc(479) LOG(INFO) Final character coverage=0.999502\n",
            "trainer_interface.cc(511) LOG(INFO) Done! preprocessed 2294 sentences.\n",
            "unigram_model_trainer.cc(138) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(142) LOG(INFO) Extracting frequent sub strings...\n",
            "unigram_model_trainer.cc(193) LOG(INFO) Initialized 48973 seed sentencepieces\n",
            "trainer_interface.cc(517) LOG(INFO) Tokenizing input sentences with whitespace: 2294\n",
            "trainer_interface.cc(527) LOG(INFO) Done! 2283\n",
            "unigram_model_trainer.cc(488) LOG(INFO) Using 2283 sentences for EM training\n",
            "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=26336 obj=413.921 num_tokens=110643 num_tokens/piece=4.20121\n",
            "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=23740 obj=377.652 num_tokens=111087 num_tokens/piece=4.67932\n",
            "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=17771 obj=384.792 num_tokens=116212 num_tokens/piece=6.53942\n",
            "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=17711 obj=381.027 num_tokens=116311 num_tokens/piece=6.56716\n",
            "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=13277 obj=396.082 num_tokens=123367 num_tokens/piece=9.29178\n",
            "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=13269 obj=392.012 num_tokens=123507 num_tokens/piece=9.30794\n",
            "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=9949 obj=410.218 num_tokens=131228 num_tokens/piece=13.1901\n",
            "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=9949 obj=406.012 num_tokens=131277 num_tokens/piece=13.195\n",
            "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=8800 obj=414.532 num_tokens=134963 num_tokens/piece=15.3367\n",
            "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=8800 obj=412.829 num_tokens=135053 num_tokens/piece=15.3469\n",
            "trainer_interface.cc(605) LOG(INFO) Saving model: m.model\n",
            "trainer_interface.cc(616) LOG(INFO) Saving vocabs: m.vocab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3FhuwRtNk2I"
      },
      "source": [
        "## トークン化 (エンコード)\n",
        "\n",
        "学習されたモデルを用いて、任意の文をエンコード(単語分割)します。分割には spm_encode コマンドを用います。--model オプションにてモデルを指定します。分割対象の文は、標準入力もしくはファイルとして与えます。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3d_WJW4OId7",
        "outputId": "df9e4517-d9f5-413b-eda3-a322a80fc31d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!echo \"吾輩は猫である。名前はまだない。\" | spm_encode --model=m.model\n",
        "!head -20 data/wagahaiwa_nekodearu.txt |  spm_encode --model=m.model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "▁吾輩は 猫 である 。 名前 はまだ ない 。\n",
            "▁吾輩は 猫 である\n",
            "▁ 夏 目 漱 石\n",
            "▁ ------------- -------------- -------------- --------------\n",
            "▁ 【 テ キ ス ト 中に 現 れる 記 号 について 】\n",
            "▁ 《 》 : ル ビ\n",
            "▁( 例 ) 吾輩 《 わが はい 》 は猫である\n",
            "▁ | : ルビの 付 く 文字 列 の 始ま りを 特 定 する 記 号\n",
            "▁( 例 ) 一番 | 獰 悪 《 どう あ く 》 な 種 族 であった\n",
            "▁[# ] : 入 力 者 注 ▁ 主 に 外 字 の 説明 や 、 傍点 の位置 の 指 定\n",
            "▁( 数 字 は 、 J I S ▁ X ▁ 0 2 1 3 の 面 区 点 番 号 または U ni co d e 、 底本 の ページ と 行 数 )\n",
            "▁( 例 ) ※[#「 言 + 墟 のつくり 」 、 第 4 水準 2 - 8 8 - 7 4 ]\n",
            "▁ 〔 〕 : アクセント分解 された 欧 文 を か こ む\n",
            "▁( 例 ) 〔 Q u id ▁a li u d ▁ es t ▁ m u li e r ▁ ni s i ▁a mic iti ae & ▁ i ni mic a 〕\n",
            "▁ アクセント分解 について の 詳 細 は下 記 U R L を 参 照 して くださ い\n",
            "▁ ht t p : / / w ww . a o z o r a . g r . j p / a c c e n t _ s e p a r a t i o n . ht m l\n",
            "▁ ------------- -------------- -------------- --------------\n",
            "▁[# 8 字下げ ] 一 [#「 一 」 は中 見出し ]\n",
            "▁ 吾輩 《 わが はい 》 は猫である 。 名前 はまだ 無い 。\n",
            "▁ どこ で 生れ たか とん と 見当 《 けん とう 》 が つか ぬ 。 何でも 薄暗 い じめ じめ した 所 で ニャー ニャー 泣 いて いた 事 だけは 記憶している 。 吾輩は ここで 始めて 人間 というもの を見た 。 しかも あとで 聞くとそれは 書生 という 人間 中 で 一番 | 獰 悪 《 どう あ く 》 な 種 族 であった そうだ 。 この 書生 という のは 時々 我々 を 捕 《 つか ま 》 えて 煮 《 に 》 て 食う という 話 である 。 しかしその 当時 は何 という 考 もなかった から 別段 恐 しい とも思わなかった 。 ただ 彼の 掌 《 て の ひら 》 に 載 せられて ス ー と 持ち上げ られた 時 何だか フ ワ フ ワ した 感じ があった ばかり である 。 掌 の上で 少し 落ち ついて 書生 の顔を見た の が いわゆる 人間 というもの の 見 始 《 み は じめ 》 であろう 。 この時 妙なもの だ と思った 感じ が 今でも 残ってい る 。 第一 毛 をもって 装飾 され べきはずの 顔が つ る つ る して まるで 薬 缶 《 や かん 》 だ 。 その後 《 ご 》 猫 にも だいぶ 逢 《 あ 》 ったが こんな 片 輪 《 かた わ 》 には 一度 も 出 会 《 で く 》 わし た事がない 。 のみならず 顔の真中 があまり に 突 起 している 。 そうして その 穴 の中から 時々 ぷ う ぷ う と 煙 《 けむ り 》 を吹く 。 どうも 咽 《 む 》 せ ぽ く て 実に 弱った 。 これが 人間の 飲む 煙草 《 た ばこ 》 というもの である事はようやく この頃 知 った 。\n",
            "▁ この 書生 の 掌 の裏 《 うち 》 で しばらく は よい 心持 に 坐って おった が 、 しばらくすると 非常な 速 力 で 運 転 し 始めた 。 書生 が動くのか 自分だけ が動くのか 分らない が 無暗 《 むやみ 》 に 眼 が 廻る 。 胸 が 悪 くなる 。 到底 《 とうてい 》 助からない と思っている と 、 ど さ りと音がして 眼 から 火 が出た 。 それ までは 記憶している が あと は何 の事 やら いくら 考え 出そうと しても 分らない 。\n",
            "1130 107 32 5 720 2230 52 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiiSaQEkO1L9"
      },
      "source": [
        "--output_format=id とすることで、トークンに対応するIDを直接出力することが可能です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqxPioK1PelX",
        "outputId": "5372d63c-2e79-40b5-a602-c5a1104816f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!echo \"吾輩は猫である。名前はまだない。\" | spm_encode --model=m.model --output_format=id\n",
        "!head -20 data/wagahaiwa_nekodearu.txt |  spm_encode --model=m.model --output_format=id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1130 107 32 5 720 2230 52 5\n",
            "1130 107 32\n",
            "36 3948 135 7300 652\n",
            "36 7085 3426 3426 3426\n",
            "36 7800 2129 7717 444 1719 611 2514 554 3914 4643 966 7716\n",
            "36 4 3 1731 624 3352\n",
            "3066 940 836 301 4 2020 145 3 6015\n",
            "36 44 1731 5225 844 26 783 2089 7 4148 2540 3905 1191 34 3914 4643\n",
            "3066 940 836 632 44 7191 559 4 251 45 26 3 20 1285 7964 818\n",
            "175 37 1731 331 281 237 3282 36 874 9 526 651 7 1422 41 6 66 6480 7 1013 1191\n",
            "3066 543 651 13 6 7710 7709 7713 36 7091 36 4621 227 719 718 7 285 5305 625 1350 4643 2018 7134 3434 4026 5505 2617 6 2663 7 3305 14 211 543 836\n",
            "3066 940 836 895 236 1098 7805 2659 8 6 580 1297 896 227 7991 782 782 7991 2063 1297 37\n",
            "36 4666 4670 1731 7081 930 7149 415 12 16 58 84\n",
            "3066 940 836 4666 7090 2352 5599 4959 4680 2352 5505 36 5679 2631 36 3984 2352 4680 2617 1927 36 3434 2349 2983 4959 3987 4671 4752 5547 36 2983 3434 3987 1266 4670\n",
            "36 7081 966 7 5542 2066 1255 3914 7134 7712 7802 12 1009 5207 33 3709 17\n",
            "36 5553 2631 3421 1731 2350 2350 6984 6986 1925 1266 1923 6964 1923 1927 1266 1925 6923 1927 1925 6963 3421 2350 1266 3410 3410 2617 5493 2631 7715 2349 2617 3421 1266 1927 1266 2631 2983 1923 5493 1925 5553 3984 6979\n",
            "36 7085 3426 3426 3426\n",
            "175 782 184 37 54 55 54 8 1628 1776 37\n",
            "36 301 4 2020 145 3 6015 5 720 2230 2449 5\n",
            "36 512 18 1127 2506 382 14 2398 4 272 213 3 10 259 102 5 246 5167 17 3696 3696 43 152 18 6131 6131 1502 90 97 70 610 3681 5 118 429 839 172 3097 2044 5 964 1339 6578 1143 197 172 114 18 632 44 7191 559 4 251 45 26 3 20 1285 7964 818 294 5 42 1143 197 126 766 4158 12 829 4 259 39 3 266 3019 4 9 3 29 2207 197 342 32 5 3287 2713 1117 197 699 2795 19 949 1825 210 6266 5 92 403 5810 4 29 7 1799 3 9 3235 3161 444 258 14 6063 338 140 304 1210 2644 1210 2644 43 869 1496 123 32 5 5810 2173 137 723 1433 1143 5927 7 10 1714 172 3097 7 79 3085 4 61 13 3696 3 669 5 875 4309 30 640 869 10 2725 5062 21 5 419 541 353 5737 2256 5980 1451 59 21 59 21 33 508 945 5346 4 41 138 3 30 5 1216 4 95 3 107 200 265 741 4 45 3 2035 187 740 2323 4 365 49 3 91 1367 15 86 529 4 18 26 3 2005 1797 5 1892 5027 3704 9 1361 583 81 5 700 63 1227 1993 766 1669 50 1669 50 14 1369 4 4342 27 3 3466 5 270 3993 4 84 3 103 1833 26 29 596 4134 5 646 598 2115 947 4 28 993 3 3097 6528 1955 470 56 5\n",
            "36 42 1143 7 5810 1823 4 112 3 18 739 13 1512 3031 9 2472 1953 10 6 3505 4601 3459 281 18 1882 1661 22 1788 5 1143 6988 4276 6988 911 10 1150 4 1066 3 9 207 10 2442 5 1684 10 559 620 5 830 4 613 3 6771 2184 14 6 128 25 5297 207 19 656 5002 5 328 1607 3681 10 291 1117 435 1253 242 516 5020 679 911 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ov9At7QPsSW"
      },
      "source": [
        "## 脱トークン化 (デコード)\n",
        "分割済みのトークン列やID列から元の文をdecode(復元)します。decode には spm_decode コマンドを用います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihUpj5OCP-wv",
        "outputId": "30d8c011-acac-4773-c382-41d7f64951e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!echo \"▁吾輩は 猫 である 。 名前 はまだ ない 。\" | spm_decode --model=m.model\n",
        "!echo \"1130 107 32 5 720 2230 52 5\" | spm_decode --model=m.model --input_format=id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "吾輩は猫である。名前はまだない。\n",
            "吾輩は猫である。名前はまだない。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm2Hw1ItP-SZ"
      },
      "source": [
        ""
      ]
    }
  ]
}